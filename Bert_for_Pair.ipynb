{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_for_Pair.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiJA4Gx5-bBJ",
        "colab_type": "code",
        "outputId": "07368266-ec18-426b-b87c-a2501e708ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8ggMj75-gj0",
        "colab_type": "code",
        "outputId": "42d7f970-46e0-4f60-ae92-ca49b28e8ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPsHUZDwQ6Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/test_task/bert.py .\n",
        "!cp /content/drive/'My Drive'/test_task/utils.py ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-n-DDAIQ8kZ",
        "colab_type": "code",
        "outputId": "5fb0723d-8c84-46ea-b95e-bec5bb72cad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from bert import *\n",
        "from utils import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 959086.77B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDb_73bVuU9C",
        "colab_type": "text"
      },
      "source": [
        "Firstly, I will define Bert as I made before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM7xGbKj-3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import pickle\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYdTPDr4RE_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig(vocab_size_or_config_json_file=32000, \n",
        "                    hidden_size=768,\n",
        "                    num_hidden_layers=12,\n",
        "                    num_attention_heads=12,\n",
        "                    intermediate_size=3072)\n",
        "\n",
        "num_labels = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGxoK6gPRE7X",
        "colab_type": "code",
        "outputId": "226d943e-2f29-411f-f4a9-6fb41fe604ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = BertForSequenceClassification(config, num_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:14<00:00, 28026816.57B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Q0TtnNu0Uc",
        "colab_type": "text"
      },
      "source": [
        "Loading the data and indexes, as we want to do a clear comparison:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WenoGnjRfi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json(\"/content/drive/My Drive/test_task/reviews.json\", lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4K6pLfORE5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/test_task/indexes.pickle', 'rb') as f:\n",
        "    indexes = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIGGU8a1RE2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_idxs, validation_idxs = indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrnr-OQ1vgrm",
        "colab_type": "text"
      },
      "source": [
        "Getting train and val datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKNR3GS8RE0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['reviewText', 'summary', 'overall']\n",
        "train = df.iloc[train_idxs][columns].astype(str)\n",
        "val = df.iloc[validation_idxs][columns].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWItaJL7vQwJ",
        "colab_type": "text"
      },
      "source": [
        "As in previous notebooks, I will shift labels on 1, to make them in the right format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piOz51f4YBrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.loc[:, 'overall'] = train.overall.astype(int).apply(lambda target: target-1)\n",
        "val.loc[:, 'overall'] = val.overall.astype(int).apply(lambda target: target-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpYWXqFAvp3B",
        "colab_type": "text"
      },
      "source": [
        "At this step I will create lists of the train and the val data for both text columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Nmolv4RExy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_rev = train['reviewText'].to_list()\n",
        "X_train_sum = train['summary'].to_list()\n",
        "y_train = train['overall'].to_list()\n",
        "\n",
        "X_val_rev = val['reviewText'].to_list()\n",
        "X_val_sum = val['summary'].to_list()\n",
        "y_val = val['overall'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7Bmx9XwEg-",
        "colab_type": "text"
      },
      "source": [
        "I will extend the functionality of text_dataset to make the ability to load to the model two sentences which will be separated by [SEP] token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRhYJMytREvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class text_pairs_dataset(text_dataset):\n",
        "\n",
        "    def __init__(self, x_y_list, max_review_length, max_summ_length, transform=None):\n",
        "        \n",
        "        self.x_y_list = x_y_list\n",
        "        self.transform = transform\n",
        "        self.max_review_length = max_review_length\n",
        "        self.max_summ_length = max_summ_length\n",
        "       \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        #indexind first sequence\n",
        "        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n",
        "        \n",
        "        if len(tokenized_review) > self.max_review_length:\n",
        "            tokenized_review = tokenized_review[:self.max_review_length]\n",
        "            \n",
        "        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n",
        "\n",
        "        padding = [0] * (self.max_review_length - len(ids_review))\n",
        "        \n",
        "        ids_review += padding\n",
        "\n",
        "        #indexind second one\n",
        "        tokenized_summ = tokenizer.tokenize(self.x_y_list[1][index])\n",
        "        \n",
        "        if len(tokenized_summ) > self.max_summ_length:\n",
        "            tokenized_summ = tokenized_summ[:self.max_summ_length]\n",
        "            \n",
        "        ids_sum  = tokenizer.convert_tokens_to_ids(tokenized_summ)\n",
        "\n",
        "        padding = [0] * (self.max_summ_length - len(ids_sum))\n",
        "        \n",
        "        ids_sum += padding\n",
        "\n",
        "        #joining them together with [SEP] token (idx of [SEP] token is 102)\n",
        "        ids = ids_review + [102] + ids_sum\n",
        "\n",
        "        assert len(ids) == self.max_review_length + self.max_summ_length + 1\n",
        "        \n",
        "        ids = torch.tensor(ids)\n",
        "        \n",
        "        sentiment = self.x_y_list[2][index] # color   \n",
        " \n",
        "        list_of_labels = [torch.from_numpy(np.array(sentiment))]\n",
        "        \n",
        "        \n",
        "        return ids, list_of_labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJsZhFZ5wrqU",
        "colab_type": "text"
      },
      "source": [
        "I will use the same lengths as I used before for review and summary fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaHYSFOREss",
        "colab_type": "code",
        "outputId": "2d8bfff8-fea7-4fd7-8ad2-8c61e9f8626b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "max_review_length = 60\n",
        "max_summ_length = 60\n",
        "\n",
        "train_lists = [X_train_rev, X_train_sum, y_train]\n",
        "val_lists = [X_val_rev, X_val_sum, y_val]\n",
        "\n",
        "training_dataset = text_pairs_dataset(x_y_list = train_lists, \n",
        "                                      max_review_length = max_review_length,\n",
        "                                      max_summ_length = max_summ_length)\n",
        "\n",
        "test_dataset = text_pairs_dataset(x_y_list = val_lists,\n",
        "                                  max_review_length = max_review_length,\n",
        "                                  max_summ_length = max_summ_length)\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, \n",
        "                                                         batch_size=batch_size, \n",
        "                                                         shuffle=True, \n",
        "                                                         num_workers=0),\n",
        "                   'val':torch.utils.data.DataLoader(test_dataset, \n",
        "                                                     batch_size=batch_size, \n",
        "                                                     shuffle=True, \n",
        "                                                     num_workers=0)}\n",
        "\n",
        "dataset_sizes = {'train':len(train_lists[0]),\n",
        "                'val':len(val_lists[0])}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikcUN2ixREqD",
        "colab_type": "code",
        "outputId": "871db970-12a5-49c1-c8ae-fddda9fabaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSjVfeiWw__k",
        "colab_type": "text"
      },
      "source": [
        "The same hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqiJ62yQSGsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "optimizer = optim.Adam([\n",
        "                        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n",
        "                        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n",
        "                      ])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 4 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "model_name = 'bert2texts'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ddvNQXSGqL",
        "colab_type": "code",
        "outputId": "269827eb-468a-4b68-be80-917b75683000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "model, raw_preds = train_model(model, model_name, criterion, optimizer, exp_lr_scheduler, dataloaders_dict, dataset_sizes, device, num_epochs=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "Epoch 1/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train total loss: 0.4862 \n",
            "train F-1 score : 0.8193 \n",
            "val total loss: 0.4133 \n",
            "val F-1 score : 0.8437 \n",
            "saving with loss of 0.4132876981496811 improved over previous 100\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train total loss: 0.3853 \n",
            "train F-1 score : 0.8525 \n",
            "val total loss: 0.3997 \n",
            "val F-1 score : 0.8465 \n",
            "saving with loss of 0.3996911370277405 improved over previous 0.4132876981496811\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train total loss: 0.3330 \n",
            "train F-1 score : 0.8710 \n",
            "val total loss: 0.4183 \n",
            "val F-1 score : 0.8505 \n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train total loss: 0.2549 \n",
            "train F-1 score : 0.9031 \n",
            "val total loss: 0.4521 \n",
            "val F-1 score : 0.8457 \n",
            "\n",
            "Training complete in 226m 14s\n",
            "Best val loss: 0.399691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82jQocl6MPal",
        "colab_type": "text"
      },
      "source": [
        "Oh, as we can see, this approach overperformed two separate models with third built on their predictions.\n",
        "\n",
        "4 epochs were too much for it, cause overfit had been started. But we saved the best model weights, so it doesn't matter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGWx8f-ZJSbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/test_task/two_sent.pickle', 'wb') as f:\n",
        "    pickle.dump(raw_preds, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WohqAHwuMLwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}